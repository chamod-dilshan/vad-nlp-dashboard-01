{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 0.5058642625808716,
      "learning_rate": 1.9755000000000003e-05,
      "loss": 0.6278,
      "step": 50
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4450160264968872,
      "learning_rate": 1.9505e-05,
      "loss": 0.5434,
      "step": 100
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7754477858543396,
      "learning_rate": 1.9255e-05,
      "loss": 0.5073,
      "step": 150
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4480896294116974,
      "learning_rate": 1.9005000000000002e-05,
      "loss": 0.4884,
      "step": 200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6855113506317139,
      "learning_rate": 1.8755000000000003e-05,
      "loss": 0.4834,
      "step": 250
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.578850507736206,
      "learning_rate": 1.8505000000000003e-05,
      "loss": 0.4783,
      "step": 300
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5799142122268677,
      "learning_rate": 1.8255e-05,
      "loss": 0.4764,
      "step": 350
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5226178169250488,
      "learning_rate": 1.8005e-05,
      "loss": 0.4798,
      "step": 400
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4422476291656494,
      "learning_rate": 1.7755000000000002e-05,
      "loss": 0.4686,
      "step": 450
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.47018226981163025,
      "learning_rate": 1.7505e-05,
      "loss": 0.4695,
      "step": 500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4744287431240082,
      "learning_rate": 1.7255000000000003e-05,
      "loss": 0.4606,
      "step": 550
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5173494815826416,
      "learning_rate": 1.7005e-05,
      "loss": 0.4758,
      "step": 600
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6878686547279358,
      "learning_rate": 1.6755e-05,
      "loss": 0.4635,
      "step": 650
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5316348075866699,
      "learning_rate": 1.6505000000000002e-05,
      "loss": 0.457,
      "step": 700
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8110190033912659,
      "learning_rate": 1.6255e-05,
      "loss": 0.4624,
      "step": 750
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6421428918838501,
      "learning_rate": 1.6005e-05,
      "loss": 0.449,
      "step": 800
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6252734065055847,
      "learning_rate": 1.5755e-05,
      "loss": 0.4447,
      "step": 850
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.48851898312568665,
      "learning_rate": 1.5505e-05,
      "loss": 0.4488,
      "step": 900
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.5130563974380493,
      "learning_rate": 1.5255000000000002e-05,
      "loss": 0.4445,
      "step": 950
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7660532593727112,
      "learning_rate": 1.5005000000000001e-05,
      "loss": 0.433,
      "step": 1000
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1818718910217285,
      "learning_rate": 1.4755000000000002e-05,
      "loss": 0.4334,
      "step": 1050
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6434009671211243,
      "learning_rate": 1.4505000000000001e-05,
      "loss": 0.4288,
      "step": 1100
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.7795523405075073,
      "learning_rate": 1.4255000000000002e-05,
      "loss": 0.4244,
      "step": 1150
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6360199451446533,
      "learning_rate": 1.4005000000000002e-05,
      "loss": 0.4183,
      "step": 1200
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9028210639953613,
      "learning_rate": 1.3755000000000001e-05,
      "loss": 0.4197,
      "step": 1250
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.7301817536354065,
      "learning_rate": 1.3505000000000002e-05,
      "loss": 0.4086,
      "step": 1300
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.5261781811714172,
      "learning_rate": 1.3255e-05,
      "loss": 0.4172,
      "step": 1350
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.4030208587646484,
      "learning_rate": 1.3005000000000002e-05,
      "loss": 0.4076,
      "step": 1400
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.679344654083252,
      "learning_rate": 1.2755000000000002e-05,
      "loss": 0.3914,
      "step": 1450
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.2140400409698486,
      "learning_rate": 1.2505e-05,
      "loss": 0.4063,
      "step": 1500
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.0239756107330322,
      "learning_rate": 1.2255000000000002e-05,
      "loss": 0.395,
      "step": 1550
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9339519143104553,
      "learning_rate": 1.2005e-05,
      "loss": 0.3964,
      "step": 1600
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.7981200218200684,
      "learning_rate": 1.1755e-05,
      "loss": 0.3862,
      "step": 1650
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.9533164501190186,
      "learning_rate": 1.1505000000000003e-05,
      "loss": 0.3855,
      "step": 1700
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7972938418388367,
      "learning_rate": 1.1255e-05,
      "loss": 0.3839,
      "step": 1750
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.8404194116592407,
      "learning_rate": 1.1005e-05,
      "loss": 0.3768,
      "step": 1800
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.5638080835342407,
      "learning_rate": 1.0755e-05,
      "loss": 0.388,
      "step": 1850
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.7293661236763,
      "learning_rate": 1.0505e-05,
      "loss": 0.3754,
      "step": 1900
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.8845489621162415,
      "learning_rate": 1.0255000000000001e-05,
      "loss": 0.3779,
      "step": 1950
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.6283655166625977,
      "learning_rate": 1.0005e-05,
      "loss": 0.3771,
      "step": 2000
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.4898192882537842,
      "learning_rate": 9.755e-06,
      "loss": 0.3848,
      "step": 2050
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.200827121734619,
      "learning_rate": 9.505000000000001e-06,
      "loss": 0.3761,
      "step": 2100
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.255595326423645,
      "learning_rate": 9.255e-06,
      "loss": 0.3726,
      "step": 2150
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6297454833984375,
      "learning_rate": 9.005000000000001e-06,
      "loss": 0.3656,
      "step": 2200
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.195526123046875,
      "learning_rate": 8.755e-06,
      "loss": 0.3677,
      "step": 2250
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.5451501607894897,
      "learning_rate": 8.505e-06,
      "loss": 0.3724,
      "step": 2300
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.3323252201080322,
      "learning_rate": 8.255000000000001e-06,
      "loss": 0.3567,
      "step": 2350
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.5562227964401245,
      "learning_rate": 8.005e-06,
      "loss": 0.3509,
      "step": 2400
    },
    {
      "epoch": 2.45,
      "grad_norm": 1.5918488502502441,
      "learning_rate": 7.755000000000001e-06,
      "loss": 0.372,
      "step": 2450
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.0405465364456177,
      "learning_rate": 7.505e-06,
      "loss": 0.3547,
      "step": 2500
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.9350302219390869,
      "learning_rate": 7.255000000000001e-06,
      "loss": 0.3486,
      "step": 2550
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.1971746683120728,
      "learning_rate": 7.005000000000001e-06,
      "loss": 0.3484,
      "step": 2600
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.203505039215088,
      "learning_rate": 6.7550000000000005e-06,
      "loss": 0.3552,
      "step": 2650
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.006333351135254,
      "learning_rate": 6.505e-06,
      "loss": 0.3486,
      "step": 2700
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.5490320920944214,
      "learning_rate": 6.255e-06,
      "loss": 0.3391,
      "step": 2750
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.3716884851455688,
      "learning_rate": 6.005000000000001e-06,
      "loss": 0.3652,
      "step": 2800
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.183282732963562,
      "learning_rate": 5.755000000000001e-06,
      "loss": 0.3488,
      "step": 2850
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.9371382594108582,
      "learning_rate": 5.505000000000001e-06,
      "loss": 0.3514,
      "step": 2900
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.54531991481781,
      "learning_rate": 5.2550000000000005e-06,
      "loss": 0.3403,
      "step": 2950
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.314748525619507,
      "learning_rate": 5.0049999999999995e-06,
      "loss": 0.3344,
      "step": 3000
    },
    {
      "epoch": 3.05,
      "grad_norm": 1.5680111646652222,
      "learning_rate": 4.755e-06,
      "loss": 0.3456,
      "step": 3050
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.7271802425384521,
      "learning_rate": 4.505e-06,
      "loss": 0.3415,
      "step": 3100
    },
    {
      "epoch": 3.15,
      "grad_norm": 2.974290132522583,
      "learning_rate": 4.255e-06,
      "loss": 0.3312,
      "step": 3150
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.6284278631210327,
      "learning_rate": 4.005000000000001e-06,
      "loss": 0.3362,
      "step": 3200
    },
    {
      "epoch": 3.25,
      "grad_norm": 2.421013355255127,
      "learning_rate": 3.7550000000000005e-06,
      "loss": 0.3387,
      "step": 3250
    },
    {
      "epoch": 3.3,
      "grad_norm": 3.3430538177490234,
      "learning_rate": 3.505e-06,
      "loss": 0.3433,
      "step": 3300
    },
    {
      "epoch": 3.35,
      "grad_norm": 2.278658390045166,
      "learning_rate": 3.255e-06,
      "loss": 0.3302,
      "step": 3350
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.263524055480957,
      "learning_rate": 3.005e-06,
      "loss": 0.3271,
      "step": 3400
    },
    {
      "epoch": 3.45,
      "grad_norm": 1.4196768999099731,
      "learning_rate": 2.7550000000000003e-06,
      "loss": 0.3372,
      "step": 3450
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.035888195037842,
      "learning_rate": 2.505e-06,
      "loss": 0.3357,
      "step": 3500
    },
    {
      "epoch": 3.55,
      "grad_norm": 1.0348925590515137,
      "learning_rate": 2.2550000000000004e-06,
      "loss": 0.3396,
      "step": 3550
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.4862957000732422,
      "learning_rate": 2.0050000000000003e-06,
      "loss": 0.3291,
      "step": 3600
    },
    {
      "epoch": 3.65,
      "grad_norm": 1.191016435623169,
      "learning_rate": 1.7550000000000001e-06,
      "loss": 0.3273,
      "step": 3650
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.7292901277542114,
      "learning_rate": 1.505e-06,
      "loss": 0.3396,
      "step": 3700
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.8369402885437012,
      "learning_rate": 1.255e-06,
      "loss": 0.3208,
      "step": 3750
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.701151967048645,
      "learning_rate": 1.0050000000000001e-06,
      "loss": 0.3304,
      "step": 3800
    },
    {
      "epoch": 3.85,
      "grad_norm": 3.158489942550659,
      "learning_rate": 7.550000000000001e-07,
      "loss": 0.3437,
      "step": 3850
    },
    {
      "epoch": 3.9,
      "grad_norm": 1.4454421997070312,
      "learning_rate": 5.05e-07,
      "loss": 0.348,
      "step": 3900
    },
    {
      "epoch": 3.95,
      "grad_norm": 1.4917490482330322,
      "learning_rate": 2.55e-07,
      "loss": 0.3331,
      "step": 3950
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.2251919507980347,
      "learning_rate": 5e-09,
      "loss": 0.3412,
      "step": 4000
    }
  ],
  "logging_steps": 50,
  "max_steps": 4000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 229531631616000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
